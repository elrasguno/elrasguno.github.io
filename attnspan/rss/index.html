<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[attnspan]]></title><description><![CDATA[Ramblings About Software Engineering, Photography, And Then Some]]></description><link>elrasguno.github.io//</link><image><url>elrasguno.github.io//favicon.png</url><title>attnspan</title><link>elrasguno.github.io//</link></image><generator>Ghost 4.48</generator><lastBuildDate>Sat, 21 May 2022 22:30:49 GMT</lastBuildDate><atom:link href="elrasguno.github.io//rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Captain Not-Too-Obvious â„¢ Explains How to Improve Node.js Service CPU Performance]]></title><description><![CDATA[<p><em>This is the second in a series of posts about load testing services built on Node.js</em></p><p>When the platform team at WB Games in San Francisco began the endeavor of testing and optimizing our services code, we weren&#x2019;t expecting it to be so. hard! Code we thought</p>]]></description><link>elrasguno.github.io//captain-not-too-obvious-explains-how-to-improve-node-js-service-cpu-performance/</link><guid isPermaLink="false">6288c77ad46d920e03baf08d</guid><dc:creator><![CDATA[Dan Racanelli]]></dc:creator><pubDate>Sat, 21 May 2022 09:26:06 GMT</pubDate><content:encoded><![CDATA[<p><em>This is the second in a series of posts about load testing services built on Node.js</em></p><p>When the platform team at WB Games in San Francisco began the endeavor of testing and optimizing our services code, we weren&#x2019;t expecting it to be so. hard! Code we thought was totally innocuous snuck up and bit us, and code that we were certain would come back to haunt us &#x2026; well, it haunted us, too. Through use of a variety of tools and techniques that will be described over a series of posts, we&#x2019;ll explain what helped us achieve optimal performance from Node.js services under heavy concurrent traffic.</p><p><strong>Such Concurrency. Much Request. Wow</strong></p><p>I&#x2019;ve found it challenging to find information about what people are trying to test when they talk about Node.js load testing. That being the case, I&#x2019;m going to jump in head first and be as transparent as I can. First, understand is that the goal of WB Games Platform is to handle requests on behalf of millions of users per day, without eating into the bottom line of our game studios. That is to say, we&#x2019;re not interested in just throwing money at <a href="http://en.wikipedia.org/wiki/Scalability#Horizontal_and_vertical_scaling">horizontal scaling</a> and calling it a day. Second, I&#x2019;d worked with services on stacks in the past that where inefficiency was king and service nodes were only capable of handling low hundreds of CCU, when I&#x2019;d come into building this platform of the mindset that our service nodes should be able to handle high thousands of CCU.</p><p>Again, for the sake of transparency, I&#x2019;ll qualify our idea of what &#x201C;heavy current traffic&#x201D; is. My original, mythical target was that each production service node, doing a moderate amount of CPU bound work, could handle 10,000 concurrent requests per second. What&#x2019;s the machine, you ask? Good question. Depending on the to-be-specified-shortly job description of the node, it would be either a 4-Core VM or an 8-Core VM on <a href="http://azure.microsoft.com/">Microsoft Azure</a>.</p><p>So! If an 8-Core VM can do 10k CCU, then the crappiest, 1-Core VM &#x2014; an &#x201C;A1&#x201D; with 1.75gb RAM and ~2.0GHz CPI &#x2014; can do 1250 CCU, right? RiGhT?!</p><p><strong>Target Performance Metrics</strong></p><p>Before this bit drifts away into the ether, here the metrics we measure our services&#x2019; performance against, and the targets we wanted to hit, in priority order.</p><ul><li>CPU Usage &lt;= 80%</li><li>Response Times &lt;= 100ms</li><li>Errors = 0</li></ul><p><strong>The Job Description</strong></p><p>As promised, here is the CPU performance best case scenario:</p><ul><li>Existing user with cached (in <a href="http://redis.io/">Redis</a>) &#x201C;profile&#x201D; data comes to a service.</li><li>Authentication token is successfully validated against cached data (i.e call Redis via an already connected persistent connection).</li><li>User &#x201C;profile&#x201D; data is retrieved from cache and stored in a reference object.</li><li>Logic operates on and manipulates reference object.</li><li>User &#x201C;profile&#x201D; data is stored in cache, client receives successful response.</li><li>Secondary system is notified (via <a href="http://redis.io/topics/data-types-intro#redis-lists">Redis List/Queue</a>) to persist data to <a href="http://www.mongodb.org/">MongoDB</a>.</li></ul><p>Here is the one worst case scenario:</p><ul><li>Existing user&#x2019;s &#x201C;profile&#x201D; data has expired from the cache</li><li>Read from MongoDB</li><li>Repopulate cache</li><li>Store data in a reference object</li><li>Logic operates on and manipulates reference object, a lot ...</li><li>User &#x201C;profile&#x201D; data is stored in cache, client receives successful response.</li><li>Secondary system is notified (via Redis List/Queue) to persist data to MongoDB</li></ul><p><strong>OK then, 10k CCU, here we come!</strong></p><p>Having followed the tips outlined in the <a href="http://attnspan.com/blog/tips-for-running-load-tests-with-apache-jmeter">first part</a> of this series, we fired up JMeter and were off to the races. As the ramp-up progresses, everything looks fine, but as we near our peak of 1250 CCU, the CPU usage spikes to 100%! Also, as we see the <a href="http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages">load average</a> of the VM head towards 1.0, we see the response times increase from ~300ms to as much as ~3000ms! In a word &#x2026; yuck!</p><p>Things looked pretty bleak at that point given our target of 80% CPU and 100ms response times, but thankfully there are plenty of things we were able to do to improve the situation. After having gone through this exercise, we now ask ourselves the following questions when attempting performance optimizations.</p><p><strong>Are you logging to disk?</strong></p><p>When I started this performance optimization process, I never fully considered the CPU impact of logging to disk. If you have a service receiving tens or even low hundreds of requests per second, you can <code>console.log</code> occasionally and not really feel it. However, when you&#x2019;re attempting 1k+ requests per second, you&#x2019;re going to want to curb your logging. In our case, we&#x2019;re using the <a href="https://github.com/flatiron/winston">winston</a> logging library, and choose to override JavaScript&#x2019;s <code>console</code> object to internally use winston so that we can run our tests with a logging level that sends everything but <code>console.error</code> calls to <code>/dev/null</code> (more on this in a separate post).</p><p><em>Lesson Learned: Keep <code>console</code> from writing to disk in performance sensitive code</em></p><p><strong>Are you reading from or writing to disk at runtime?</strong></p><p>After nipping the logging issue, we found other code reading files from disk at runtime. Ack! Since we&#x2019;re building services that are long running processes, we optimized away that problem by reading each file once at service boot time, then parsing and caching the results in the Node processes memory.</p><p><em>Lesson Learned: Pre-parse and pre-cache any files that are needed at runtime at service boot time</em></p><p><strong>Are you excessively using JSON.parse or JSON.stringify?</strong></p><p>Calls to <code>JSON.parse</code> and <code>JSON.stringify</code> are exorbitantly CPU intensive. Just to clarify, it&#x2019;s not <em>slow</em>; it&#x2019;s not <em>inefficient</em>; it just happens to be a blocking operation that you don&#x2019;t want to ask a CPU to perform 1000 times a second. Just like with disk i/o, if you&#x2019;re on a system taking tens or hundreds of requests per second &#x2026; no big whoop. If you&#x2019;re trying to push 1k+ on crappy &#x201C;hardware&quot;, you&#x2019;re going to have to pull out as many of the stops that you can find.</p><p>In our case, we ended up optimizing our best case scenario so that there would be two <em>JSON.parse</em> calls and two <em>JSON.stringify</em> calls per request. Two, you ask? Well, since we&#x2019;re using HTTP, and chose explicitly to allow our game clients to use the <em>application/json</em> content-type, that&#x2019;s what we need to support. That means we&#x2019;ll be parsing an HTTP request, and JSON data coming from Redis. On the way back to the client, we&#x2019;ll be stringifying the data to go back to Redis, and the HTTP response to the client.</p><p>In the worst case scenario, we&#x2019;d be paying the additional CPU cost for using the <code>mongodb</code> library and its internal parsing calls when translating <code>bson</code> data into JavaScript objects. Additionally, in the occasional unfortunate situation where we found ourselves pulling multiple keys from the (Redis) cache -- which were nested objects and therefore stored in JSON format -- we&#x2019;d aggregate each JSON string into an array manually so we only need to call <code>JSON.parse</code> once. Here&#x2019;s an example</p><pre><code>/**
 * Aggregate multiple JSON strings into one to save on CPU.
 * 
 * @param {Array} jsonStringsArray An array of valid JSON strings to be parsed together.
 * @returns {Array} An array of JavaScript Objects, or an empty array if any members of the input array are invalid JSON.
 */
function aggregateParseJSON(jsonStringsArray)
{
    var tmpArray = &apos;[&apos; + jsonStringsArray.join(&apos;,&apos;) + &apos;]&apos;,
        parsed = [];
        
    try {
        parsed = JSON.parse(tmpArray);
    } catch (e) {}
    return parsed;
}
</code></pre><p>After we completed our <code>JSON.parse</code> and <code>JSON.stringify</code> related optimizations, we found that at 1k+ requests per second, each <code>JSON.parse</code> or <code>JSON.stringify</code> call that we could remove would net 10% less CPU usage. This, in conjunction with our disk i/o related findings, is all we need to pay attention to most of the time to identify and fix a performance bottleneck.</p><p><em>Lesson Learned: Keep calls to <code>JSON.parse</code> and <code>JSON.stringify</code> to a minimum in performance sensitive code</em></p><p><strong>Have you used process.nextTick or setImmediate where possible?</strong></p><p>If you&#x2019;re still with me, you may recall something about using &#xF8;mq to send data to a secondary system. In our case, we found that we can hit our 80% CPU usage / 100ms response time target by offloading the responsibility of persisting data to disk (via the mongodb Node library) to a secondary VM, if and only if we wrapped our calls to the &#xF8;mq library with <code>process.nextTick</code>. For most test runs, this dropped our response times from ~100ms to ~10ms.</p><p><em>Lesson Learned: Use <code>process.nextTick</code> or <code>setImmediate</code>, whichever is more appropriate in your case, for &#x201C;fire and forget&#x201D; calls</em></p><p><strong>Summary</strong></p><p>In conclusion, while any one of the aforementioned tips is very common sensible, the number of moving parts in a typical production architecture makes it hard to remember the basics. If you make adjustments to your services based on each of these suggestions, and retest each independently, I&apos;m confident that you&apos;ll get even more performance out of your apps.</p>]]></content:encoded></item><item><title><![CDATA[Tips for Running Load Tests with Apache JMeter]]></title><description><![CDATA[<!--kg-card-begin: markdown--><p>The platform team at WB Games in San Francisco was recently tasked with load testing our services so that we could optimize our Node.js code. Here are a few of our learnings about load testing with Apache JMeter.</p>
<p><a href="http://jmeter.apache.org/">Apache JMeter</a> is &quot;open source software, a 100% pure Java</p>]]></description><link>elrasguno.github.io//tips-for-running-load-tests-with-apache-jmeter/</link><guid isPermaLink="false">6288c77ad46d920e03baf08c</guid><dc:creator><![CDATA[Dan Racanelli]]></dc:creator><pubDate>Sat, 21 May 2022 09:25:00 GMT</pubDate><content:encoded><![CDATA[<!--kg-card-begin: markdown--><p>The platform team at WB Games in San Francisco was recently tasked with load testing our services so that we could optimize our Node.js code. Here are a few of our learnings about load testing with Apache JMeter.</p>
<p><a href="http://jmeter.apache.org/">Apache JMeter</a> is &quot;open source software, a 100% pure Java application designed to load test functional behavior and measure performance. It was originally designed for testing Web Applications but has since expanded to other test functions.&#x201D; JMeter is well documented, so we were up and running tests &#x2014; both locally and using <a href="http://jmeter.apache.org/usermanual/jmeter_distributed_testing_step_by_step.pdf">remote slaves</a> &#x2014; pretty quickly. The few things that caught us off guard, and caused subsequent strife, were the following:</p>
<p><strong>Running JMeter locally</strong></p>
<p>If you&#x2019;re trying to test your system with more than ~500 threads using your own machine, you&#x2019;re likely to encounter a few issues:</p>
<p>On Linux or OSX, you&#x2019;ll want to run the command <code>ulimit -n 65536</code> (or some number greater than the default of 1024) so that your machine can hold that many open &#x201C;files&#x201D; i.e network connections.<br>
You&#x2019;re also likely to encounter Java <code>java.lang.OutOfMemoryError</code> exceptions, at which point you&#x2019;ll want to take a look at this post on <a href="http://stackoverflow.com/questions/14610801/jmeter-issues-when-running-large-number-of-threads">StackOverflow</a>.</p>
<p><strong>Running JMeter on remote hosts</strong></p>
<p>Remote JMeter masters and slaves can&#x2019;t function across networks, which makes it impossible, so far as we know, to coordinate load generation from different data centers.</p>
<p>Because of this, if and when we want to run tests in production, we&#x2019;ll have to aggregate the data from different regions separately.<br>
We learned that it&#x2019;s important to attach a &#x201C;<a href="http://jmeter.apache.org/usermanual/component_reference.html#Constant_Timer">Constant Timer</a>&#x201D; to HTTP requests to limit the number of requests per interval each thread makes. In our case, forgetting to do so led to 1250 threads making requests as fast as they could, instead of (in our case) once per second.</p>
<p>We also used a JMeter plugin called <a href="http://jmeter-plugins.org/wiki/SteppingThreadGroup/">Stepping Thread Group</a>, which enabled us to specify ramp-up and ramp-down periods for our tests. Unless you&#x2019;re explicitly trying to test what happens to your system during DDoS attack, you&#x2019;ll want to check out the Stepping Thread Group plugin.</p>
<p>This is the first in what will be a series of very concise posts about load testing services built on Node.js, so that&#x2019;s pretty much it! If there&#x2019;s anything I left out that would be helpful to list here, please don&#x2019;t hesitate to reach out to me (<a href="http://twitter.com/elrasguno">@elrasguno</a>) on twitter or on <a href="https://github.com/elrasguno">github</a>.</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[And now, some landscape photography]]></title><description><![CDATA[<p>In a former life, I was a photography student at UC Boulder, and then The School of the Art Institute of Chicago, focusing primarily on what was described to me as &quot;ethereal&quot; landscape photography. My cameras of choice where the <a href="http://en.wikipedia.org/wiki/Canon_AE-1">Canon AE-1</a>, a <a href="http://www.cameraquest.com/conrf.htm">Zeiss Contax IIa</a> -- which</p>]]></description><link>elrasguno.github.io//and-now-some-landscape-photography/</link><guid isPermaLink="false">6288c77ad46d920e03baf08b</guid><dc:creator><![CDATA[Dan Racanelli]]></dc:creator><pubDate>Sat, 21 May 2022 09:22:47 GMT</pubDate><content:encoded><![CDATA[<p>In a former life, I was a photography student at UC Boulder, and then The School of the Art Institute of Chicago, focusing primarily on what was described to me as &quot;ethereal&quot; landscape photography. My cameras of choice where the <a href="http://en.wikipedia.org/wiki/Canon_AE-1">Canon AE-1</a>, a <a href="http://www.cameraquest.com/conrf.htm">Zeiss Contax IIa</a> -- which my uncle bought in Korea in the 1950s -- and a <a href="http://camerapedia.wikia.com/wiki/Polaroid_Land_Model_220">Polaroid 220 Land Cam)era</a>. I shot almost exclusively in black and white with the 35mm cameras, and ventured into color when living in Chicago with the Polaroid. In order to shoot landscapes, I would take long road trips from Colorado to the Midwest, then from Chicago to almost every corner of the US.</p><p>Gas was cheap then.</p><p>As I settled into work as a software engineer, and didn&apos;t have the time to travel as much to take pictures, or to develop film, I pretty much stopped shooting. I bought a <a href="http://en.wikipedia.org/wiki/Nikon_D70">Nikon D70</a>, but I was a 35mm purist at the time, and wasn&apos;t really interested in pursuing photography if I couldn&apos;t develop my own film etc. This was especially because at the time, digital sensors could&apos;t capture enough information to translate to black and white very well.</p><p>That was then, and some such. Now I&apos;ve acquired a <a href="http://en.wikipedia.org/wiki/Nikon_D800">Nikon D800</a>, which I&apos;m incredibly pleased to be shooting with, especially because I&apos;ve gotten over my purist issues. But before I do start shooting and manipulating images to look like I would&apos;ve wanted them to look in the old days, I thought I&apos;d post some photos I&apos;ve taken over the years.</p><p><strong>Somewhere in Texas</strong></p><figure class="kg-card kg-image-card"><a href="http://i.imgur.com/NdnoLWL.png"><img src="http://i.imgur.com/NdnoLWL.png" class="kg-image" alt loading="lazy"></a></figure><p><strong>Somewhere in New Mexico</strong></p><figure class="kg-card kg-image-card"><img src="http://i.imgur.com/FqCG6ek.png" class="kg-image" alt="Somewhere in New Mexico" loading="lazy"></figure><p><strong>Table, Texas</strong></p><figure class="kg-card kg-image-card"><img src="http://i.imgur.com/fsei5R6.jpg" class="kg-image" alt="Table, Texas" loading="lazy"></figure><p><strong>Railroad Lights, New York</strong></p><figure class="kg-card kg-image-card"><img src="http://i.imgur.com/iK9zdWw.jpg" class="kg-image" alt="Railroad Lights, New York" loading="lazy"></figure><p><strong>More Polaroids</strong></p><figure class="kg-card kg-image-card"><img src="http://i.imgur.com/IvI0XkV.jpg" class="kg-image" alt="Texas Again" loading="lazy"></figure>]]></content:encoded></item><item><title><![CDATA[How Unit Testing Saves Lives, Your Sanity]]></title><description><![CDATA[<p>For the longest time, I didn&apos;t really understand what it meant to unit test code. I remember thinking something along the lines of &quot;wait, so I write a function that adds one to a number. then I write a test to prove that it added one to</p>]]></description><link>elrasguno.github.io//how-unit-testing-saves-lives-your-sanity/</link><guid isPermaLink="false">6288c77ad46d920e03baf08a</guid><dc:creator><![CDATA[Dan Racanelli]]></dc:creator><pubDate>Sat, 21 May 2022 09:20:20 GMT</pubDate><content:encoded><![CDATA[<p>For the longest time, I didn&apos;t really understand what it meant to unit test code. I remember thinking something along the lines of &quot;wait, so I write a function that adds one to a number. then I write a test to prove that it added one to a number?&quot; It just seemed to me, as I&apos;m sure it does to many people, like extra work, and unit testing wasn&apos;t worth the overhead involved it testing all of my code. I mean, I tested it all when I was developing it, right?</p><p>Those were the good old days of back end development, when all you needed to do to test your app was hit your web interface, validate input for malicious data, and display error messages to users when they missed a spot filling in a form. Maybe you used an IDE for remote breakpoint debugging, but old school error logging usually did the trick just fine. Load page, fill form, validate error conditions, rinse, repeat.</p><p>In a mobile development world, the days of &quot;error log&quot; style debugging are long over. If you&apos;re at a small shop, you may have the luxury of having control of the whole stack and codebase. Even then, the typical mobile stack is comprised of a C/Obj-C/Java layer, proxying software (<a href="https://www.charlesproxy.com/">Charles Proxy</a> etc) to deal with firewalls, back end code, and a data storage layer. When working on larger teams of both client, server, and third party server developers, it&apos;s incredibly common to get blocked by someone else&apos;s bug, making it impossible to even hit your code until the problem is fixed upstream.</p><p>On a recent project of mine, I found myself blocked like this on a very regular basis, so much so that I was given time to learn how to use unit testing to save countless time and energy while developing features.</p><h3 id="the-problem">The Problem</h3><p>I was tasked with building a sizable API in a short timeframe -- sound familiar? -- and my only mechanism for testing my code was a mobile client. The client was also in development, and was understandably buggy. It was inefficient to try and test my code from the client, because on a daily basis, something went wrong, and I was SOL for hours at a time. This approach also forced me through an entire stack worth of code when it was preferable to test small units of code independently.</p><h3 id="the-solution">The Solution</h3><p>Unit Testing to the rescue! By setting up <a href="https://github.com/sebastianbergmann/phpunit/">PHPUnit</a> on a CentOs server -- which incidentally required a slight hacking of its code to run with PHP 5.2.x -- I was able to test all of my features without needing to use the client for weeks at a time. For any given new feature, immediately after writing an API method I would write unit tests to serve the following purposes</p><p>Validating that the method behaved as expected with correct input<br>Validating that the method behaved as expected with incorrect input<br>Verifying that the tests have achieved 100% code coverage of the new method<br>One important distinction that was lost on me was the difference between assertion testing and code coverage testing. Assertion testing involves validating that your API methods return the proper output based on correct and incorrect input. Code coverage_ testing involves writing enough tests so that every line of your API code is hit by the tests.</p><h3 id="what-have-unit-tests-done-for-me-lately">What have unit tests done for me lately?</h3><p>By running the unit tests on a regular basis when code is updated, you can verify that no one has made changes that break the expected functionality of your API. Similarly, unit tests of known, valid input to third party APIs can alert you when something has changed underneath your working code to break it. If new changes do break the API, then you can update the tests accordingly, and move on knowing that your production code is working as expected. Additionally, unit tests also serve as bite-size examples of how to use an API.</p><h3 id="i-still-think-its-too-much-work-convince-me-otherwise">I still think it&apos;s too much work. Convince me otherwise</h3><p>For a medium to large codebase that&apos;s not at all unit tested, you&apos;re right. I ended up starting by using bug fixing time as an opportunity to refactor code and write tests against my bug fixes. This breaks up the work, and over time helps to stabilize an unruly codebase. The greater your code coverage, the quicker it is to locate and extinguish fires when your team is small.</p><p>Some tips for the up and coming unit tester</p><p>These tips might be of use to you</p><ul><li>Keep your methods small and remember to stay <a href="http://en.wikipedia.org/wiki/Dont_repeat_yourself">DRY</a>.</li><li>Think about what your method signatures should be in order for them to be easily testable.</li><li>Check out <a href="http://jenkins-ci.org/">Jenkins</a> if you haven&apos;t already.</li></ul>]]></content:encoded></item></channel></rss>